{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "29f6cd99",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from sqlalchemy import create_engine, Column, Integer, String, Float, DateTime\n",
    "from sqlalchemy.orm import sessionmaker, declarative_base\n",
    "\n",
    "# No need for RunnableConfig or relationship in this schema file\n",
    "# from langchain_core.runnables.config import RunnableConfig\n",
    "# from sqlalchemy.orm import relationship\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "# --- IMPORTANT: Updated to point to your new database ---\n",
    "DATABASE_URL = os.getenv(\"DATABASE_URL\", \"sqlite:///netcdf_database.db\")\n",
    "engine = create_engine(DATABASE_URL)\n",
    "SessionLocal = sessionmaker(autocommit=False, autoflush=False, bind=engine)\n",
    "Base = declarative_base()\n",
    "\n",
    "\n",
    "# Definition of the Ocean Data table\n",
    "# This class maps directly to the 'ocean_data' table created from your NetCDF file.\n",
    "class OceanData(Base):\n",
    "    __tablename__ = \"ocean_data\"\n",
    "\n",
    "    # It's good practice to have a primary key, even if not in the original file\n",
    "    id = Column(Integer, primary_key=True, index=True)\n",
    "    \n",
    "    # Coordinates from the NetCDF file\n",
    "    time = Column(DateTime)\n",
    "    latitude = Column(Float)\n",
    "    longitude = Column(Float)\n",
    "    depth = Column(Float)\n",
    "    \n",
    "    # Variables from the NetCDF file\n",
    "    so = Column(Float)       # Sea Water Salinity\n",
    "    thetao = Column(Float)   # Sea Water Potential Temperature\n",
    "    uo = Column(Float)       # Eastward Sea Water Velocity\n",
    "    vo = Column(Float)       # Northward Sea Water Velocity\n",
    "    zos = Column(Float)      # Sea Surface Height Above Geoid\n",
    "\n",
    "# Example of how to create the table if needed (the setup_db.py already did this)\n",
    "# if __name__ == \"__main__\":\n",
    "#     print(\"Creating database tables...\")\n",
    "#     Base.metadata.create_all(bind=engine)\n",
    "#     print(\"Tables created.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b52b71ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\apran\\AppData\\Local\\Temp\\ipykernel_16588\\2069348147.py:50: LangChainDeprecationWarning: The class `ChatOllama` was deprecated in LangChain 0.3.1 and will be removed in 1.0.0. An updated version of the class exists in the :class:`~langchain-ollama package and should be used instead. To use it run `pip install -U :class:`~langchain-ollama` and import as `from :class:`~langchain_ollama import ChatOllama``.\n",
      "  llm = ChatOllama(model=\"phi3\", temperature=0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating new database 'ocean_csv_database.db' from 'C:\\Users\\apran\\Videos\\Cin\\LIBRARY\\SQL Agent for Sensor Data\\ocean_data.csv'...\n",
      "✅ Successfully loaded 102393 rows into table 'ocean_data'.\n",
      "\n",
      "SQL Agent for Ocean Data is ready. Ask a question.\n",
      "\n",
      "--- Agent Execution Log ---\n",
      "Retrieved database schema.\n",
      "Checking relevance of the question: what is the depth for latitude 64.33334 and longitude -3.4166667?\n",
      "Relevance determined: relevant\n",
      "--- Event: check_relevance ---\n",
      "{'question': 'what is the depth for latitude 64.33334 and longitude -3.4166667?', 'attempts': 0, 'relevance': 'relevant'}\n",
      "Retrieved database schema.\n",
      "Converting question to SQL: what is the depth for latitude 64.33334 and longitude -3.4166667?\n",
      "Generated SQL query: SELECT * FROM ocean_data ORDER BY (latitude - 64.33334)*(latitude - 64.33334) + (longitude - -3.4166667)*(longitude - -3.4166667) ASC LIMIT 1;\n",
      "--- Event: convert_to_sql ---\n",
      "{'question': 'what is the depth for latitude 64.33334 and longitude -3.4166667?', 'attempts': 0, 'relevance': 'relevant', 'sql_query': 'SELECT * FROM ocean_data ORDER BY (latitude - 64.33334)*(latitude - 64.33334) + (longitude - -3.4166667)*(longitude - -3.4166667) ASC LIMIT 1;'}\n",
      "Executing SQL query: SELECT * FROM ocean_data ORDER BY (latitude - 64.33334)*(latitude - 64.33334) + (longitude - -3.4166667)*(longitude - -3.4166667) ASC LIMIT 1;\n",
      "Raw SQL Query Result: [{'time': '2025-09-12 23:00:00', 'depth': 0.494025, 'latitude': 19.75, 'longitude': 62.66668, 'so': 36.00756, 'thetao': 26.073544, 'uo': 0.0337825, 'vo': -0.06343201, 'zos': 0.1954587}]\n",
      "--- Event: execute_sql ---\n",
      "{'question': 'what is the depth for latitude 64.33334 and longitude -3.4166667?', 'sql_query': 'SELECT * FROM ocean_data ORDER BY (latitude - 64.33334)*(latitude - 64.33334) + (longitude - -3.4166667)*(longitude - -3.4166667) ASC LIMIT 1;', 'attempts': 0, 'relevance': 'relevant', 'query_rows': [{'time': '2025-09-12 23:00:00', 'depth': 0.494025, 'latitude': 19.75, 'longitude': 62.66668, 'so': 36.00756, 'thetao': 26.073544, 'uo': 0.0337825, 'vo': -0.06343201, 'zos': 0.1954587}], 'query_result': 'Query returned 1 rows.', 'sql_error': False}\n",
      "Generating a human-readable answer.\n",
      "Generated human-readable answer.\n",
      "--- Event: generate_human_readable_answer ---\n",
      "{'question': 'what is the depth for latitude 64.33334 and longitude -3.4166667?', 'sql_query': 'SELECT * FROM ocean_data ORDER BY (latitude - 64.33334)*(latitude - 64.33334) + (longitude - -3.4166667)*(longitude - -3.4166667) ASC LIMIT 1;', 'query_result': '\"The closest recorded depth to latitude 64.33334 and longitude -3.4166667 is approximately 0.494025 meters.\"', 'query_rows': [{'time': '2025-09-12 23:00:00', 'depth': 0.494025, 'latitude': 19.75, 'longitude': 62.66668, 'so': 36.00756, 'thetao': 26.073544, 'uo': 0.0337825, 'vo': -0.06343201, 'zos': 0.1954587}], 'attempts': 0, 'relevance': 'relevant', 'sql_error': False}\n",
      "\n",
      "==================================================\n",
      "✅ Final Human-Readable Answer:\n",
      "==================================================\n",
      "\"The closest recorded depth to latitude 64.33334 and longitude -3.4166667 is approximately 0.494025 meters.\"\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from dotenv import load_dotenv\n",
    "from typing_extensions import TypedDict\n",
    "from pydantic import BaseModel, Field\n",
    "from langchain_community.chat_models import ChatOllama\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.output_parsers import StrOutputParser, PydanticOutputParser\n",
    "from sqlalchemy import create_engine, text, inspect\n",
    "from sqlalchemy.orm import sessionmaker\n",
    "from langgraph.graph import StateGraph, END\n",
    "\n",
    "# --- Part 1: Database Setup from CSV ---\n",
    "\n",
    "def setup_database_from_csv(csv_filepath, db_filepath, table_name):\n",
    "    \"\"\"\n",
    "    Reads a CSV file, cleans its data, and loads it into an SQLite database.\n",
    "    This function will only run if the database file does not already exist.\n",
    "    \"\"\"\n",
    "    if os.path.exists(db_filepath):\n",
    "        print(f\"Database '{db_filepath}' already exists. Skipping creation.\")\n",
    "        return\n",
    "\n",
    "    print(f\"Creating new database '{db_filepath}' from '{csv_filepath}'...\")\n",
    "    try:\n",
    "        df = pd.read_csv(csv_filepath)\n",
    "        # Clean column names to be valid SQL identifiers\n",
    "        df.columns = df.columns.str.strip().str.lower().str.replace(' ', '_').str.replace('(', '').str.replace(')', '')\n",
    "        \n",
    "        engine = create_engine(f\"sqlite:///{db_filepath}\")\n",
    "        df.to_sql(table_name, engine, if_exists='replace', index=False, chunksize=10000)\n",
    "        \n",
    "        print(f\"✅ Successfully loaded {len(df)} rows into table '{table_name}'.\")\n",
    "    except FileNotFoundError:\n",
    "        print(f\"❌ Error: The CSV file was not found at {csv_filepath}\")\n",
    "    except Exception as e:\n",
    "        print(f\"❌ An error occurred while creating the database: {e}\")\n",
    "\n",
    "# --- Part 2: Agent Configuration ---\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "# Database connection setup\n",
    "DB_FILE = \"ocean_csv_database.db\"\n",
    "DATABASE_URL = os.getenv(\"DATABASE_URL\", f\"sqlite:///{DB_FILE}\")\n",
    "engine = create_engine(DATABASE_URL)\n",
    "SessionLocal = sessionmaker(autocommit=False, autoflush=False, bind=engine)\n",
    "\n",
    "# Connect to the Ollama model\n",
    "llm = ChatOllama(model=\"phi3\", temperature=0)\n",
    "\n",
    "# Define the agent's state\n",
    "class AgentState(TypedDict):\n",
    "    question: str\n",
    "    sql_query: str\n",
    "    query_result: str\n",
    "    query_rows: list\n",
    "    attempts: int\n",
    "    relevance: str\n",
    "    sql_error: bool\n",
    "\n",
    "# --- Part 3: Agent Nodes (Functions) ---\n",
    "\n",
    "def get_database_schema(engine):\n",
    "    \"\"\"Inspects the database and returns its schema as a string.\"\"\"\n",
    "    inspector = inspect(engine)\n",
    "    schema = \"\"\n",
    "    for table_name in inspector.get_table_names():\n",
    "        schema += f\"Table: {table_name}\\n\"\n",
    "        for column in inspector.get_columns(table_name):\n",
    "            col_name = column[\"name\"]\n",
    "            col_type = str(column[\"type\"])\n",
    "            schema += f\"- {col_name}: {col_type}\\n\"\n",
    "        schema += \"\\n\"\n",
    "    print(\"Retrieved database schema.\")\n",
    "    return schema\n",
    "\n",
    "class CheckRelevance(BaseModel):\n",
    "    relevance: str = Field(description=\"'relevant' or 'not_relevant'.\")\n",
    "\n",
    "def check_relevance(state: AgentState):\n",
    "    \"\"\"Checks if the user's question is relevant to the ocean data schema.\"\"\"\n",
    "    question = state[\"question\"]\n",
    "    schema = get_database_schema(engine)\n",
    "    print(f\"Checking relevance of the question: {question}\")\n",
    "    \n",
    "    system = \"\"\"You are an assistant that determines if a question is related to the database schema of oceanographic data.\n",
    "    A question is relevant if it asks about sea temperature, salinity, velocity, coordinates, depth, or time.\n",
    "    Schema: {schema}\n",
    "    Respond with a JSON object with a single key 'relevance' and a value of 'relevant' or 'not_relevant'.\"\"\".format(schema=schema)\n",
    "    \n",
    "    check_prompt = ChatPromptTemplate.from_messages([(\"system\", system), (\"human\", \"Question: {question}\")])\n",
    "    parser = PydanticOutputParser(pydantic_object=CheckRelevance)\n",
    "    relevance_checker = check_prompt | llm.bind(format=\"json\") | parser\n",
    "    \n",
    "    relevance = relevance_checker.invoke({\"question\": question})\n",
    "    state[\"relevance\"] = relevance.relevance\n",
    "    print(f\"Relevance determined: {state['relevance']}\")\n",
    "    return state\n",
    "\n",
    "class ConvertToSQL(BaseModel):\n",
    "    sql_query: str = Field(description=\"The SQL query for the user's question.\")\n",
    "\n",
    "def convert_nl_to_sql(state: AgentState):\n",
    "    \"\"\"Converts the natural language question to a robust SQL query.\"\"\"\n",
    "    question = state[\"question\"]\n",
    "    schema = get_database_schema(engine)\n",
    "    print(f\"Converting question to SQL: {question}\")\n",
    "\n",
    "    system = \"\"\"You are an expert SQL assistant. Convert natural language questions into robust SQL queries based on the provided schema.\n",
    "    The table is named 'ocean_data'.\n",
    "    IMPORTANT: The data exists on a grid. Do not use exact equality checks (e.g., WHERE latitude = 50).\n",
    "    Instead, find the NEAREST available data point by using an ORDER BY clause with a squared distance calculation and then taking the first result (LIMIT 1).\n",
    "    Example for latitude 50 and longitude -10: 'SELECT * FROM ocean_data ORDER BY (latitude - 50.0)*(latitude - 50.0) + (longitude - -10.0)*(longitude - -10.0) ASC LIMIT 1;'\n",
    "    Pay close attention to the column names provided in the schema.\n",
    "    Schema: {schema}\n",
    "    Respond with a JSON object with a single key 'sql_query' containing only the SQL query.\"\"\".format(schema=schema)\n",
    "    \n",
    "    convert_prompt = ChatPromptTemplate.from_messages([(\"system\", system), (\"human\", \"{question}\")])\n",
    "    parser = PydanticOutputParser(pydantic_object=ConvertToSQL)\n",
    "    sql_generator = convert_prompt | llm.bind(format=\"json\") | parser\n",
    "    \n",
    "    result = sql_generator.invoke({\"question\": question})\n",
    "    state[\"sql_query\"] = result.sql_query\n",
    "    print(f\"Generated SQL query: {state['sql_query']}\")\n",
    "    return state\n",
    "\n",
    "def execute_sql(state: AgentState):\n",
    "    \"\"\"Executes the SQL query and returns the result.\"\"\"\n",
    "    sql_query = state[\"sql_query\"].strip()\n",
    "    session = SessionLocal()\n",
    "    print(f\"Executing SQL query: {sql_query}\")\n",
    "    try:\n",
    "        result = session.execute(text(sql_query))\n",
    "        if sql_query.lower().strip().startswith(\"select\"):\n",
    "            rows = result.fetchall()\n",
    "            columns = result.keys()\n",
    "            state[\"query_rows\"] = [dict(zip(columns, row)) for row in rows]\n",
    "            state[\"query_result\"] = f\"Query returned {len(state['query_rows'])} rows.\"\n",
    "            print(f\"Raw SQL Query Result: {state['query_rows']}\")\n",
    "        else:\n",
    "            session.commit()\n",
    "            state[\"query_result\"] = \"The action has been successfully completed.\"\n",
    "        state[\"sql_error\"] = False\n",
    "    except Exception as e:\n",
    "        state[\"query_result\"] = f\"Error executing SQL query: {str(e)}\"\n",
    "        state[\"sql_error\"] = True\n",
    "        print(f\"Error executing SQL query: {str(e)}\")\n",
    "    finally:\n",
    "        session.close()\n",
    "    return state\n",
    "\n",
    "def generate_human_readable_answer(state: AgentState):\n",
    "    \"\"\"Generates a clear, natural language response from the query results.\"\"\"\n",
    "    question = state[\"question\"]\n",
    "    query_rows = state.get(\"query_rows\", [])\n",
    "    sql_error = state.get(\"sql_error\", False)\n",
    "    print(\"Generating a human-readable answer.\")\n",
    "\n",
    "    system = \"You are an assistant who explains database query results about oceanographic data in a clear and concise way.\"\n",
    "    \n",
    "    prompt_text = \"\"\n",
    "    if sql_error:\n",
    "        prompt_text = f\"The query for the question '{question}' failed. Explain the error in a simple sentence: {state['query_result']}\"\n",
    "    elif not query_rows:\n",
    "        prompt_text = f\"Based on the question '{question}', formulate a single sentence stating that no data was found for the specified criteria.\"\n",
    "    else:\n",
    "        data_summary = \", \".join([str(row) for row in query_rows])\n",
    "        prompt_text = f\"\"\"The user asked: '{question}'.\n",
    "        The database returned the following data: {data_summary}.\n",
    "        Formulate a clear, natural language answer summarizing this data in a single sentence. Mention the specific value requested and the coordinates found.\n",
    "        For example: 'At the nearest point (latitude X, longitude Y), the depth is Z meters.'\"\"\"\n",
    "    \n",
    "    generate_prompt = ChatPromptTemplate.from_messages([(\"system\", system), (\"human\", \"{input_text}\")])\n",
    "    human_response = generate_prompt | llm | StrOutputParser()\n",
    "    answer = human_response.invoke({\"input_text\": prompt_text})\n",
    "    \n",
    "    state[\"query_result\"] = answer\n",
    "    print(\"Generated human-readable answer.\")\n",
    "    return state\n",
    "\n",
    "class RewrittenQuestion(BaseModel):\n",
    "    question: str = Field(description=\"The rewritten question.\")\n",
    "\n",
    "def regenerate_query(state: AgentState):\n",
    "    question = state[\"question\"]\n",
    "    print(\"Regenerating the SQL query by rewriting the question.\")\n",
    "    system = \"\"\"You are an assistant that reformulates a question about oceanographic data to be more precise for SQL conversion.\n",
    "    Ensure that details like latitude, longitude, and depth are clearly stated.\n",
    "    Respond with a JSON object with a single key 'question' containing the rewritten question.\"\"\"\n",
    "    \n",
    "    rewrite_prompt = ChatPromptTemplate.from_messages([(\"system\", system), (\"human\", \"Original Question: {question}\")])\n",
    "    parser = PydanticOutputParser(pydantic_object=RewrittenQuestion)\n",
    "    rewriter = rewrite_prompt | llm.bind(format=\"json\") | parser\n",
    "    \n",
    "    rewritten = rewriter.invoke({\"question\": question})\n",
    "    state[\"question\"] = rewritten.question\n",
    "    state[\"attempts\"] += 1\n",
    "    print(f\"Rewritten question: {state['question']}\")\n",
    "    return state\n",
    "\n",
    "# --- Part 4: Graph Definition and Execution ---\n",
    "\n",
    "# Build the graph\n",
    "workflow = StateGraph(AgentState)\n",
    "workflow.add_node(\"check_relevance\", check_relevance)\n",
    "workflow.add_node(\"convert_to_sql\", convert_nl_to_sql)\n",
    "workflow.add_node(\"execute_sql\", execute_sql)\n",
    "workflow.add_node(\"generate_human_readable_answer\", generate_human_readable_answer)\n",
    "workflow.add_node(\"regenerate_query\", regenerate_query)\n",
    "\n",
    "workflow.set_entry_point(\"check_relevance\")\n",
    "\n",
    "def relevance_router(state: AgentState):\n",
    "    return \"convert_to_sql\" if state[\"relevance\"].lower() == \"relevant\" else END\n",
    "\n",
    "def execute_sql_router(state: AgentState):\n",
    "    return \"generate_human_readable_answer\" if not state.get(\"sql_error\", False) else \"regenerate_query\"\n",
    "\n",
    "def check_attempts_router(state: AgentState):\n",
    "    return \"convert_to_sql\" if state[\"attempts\"] < 3 else END\n",
    "\n",
    "workflow.add_conditional_edges(\"check_relevance\", relevance_router)\n",
    "workflow.add_edge(\"convert_to_sql\", \"execute_sql\")\n",
    "workflow.add_conditional_edges(\"execute_sql\", execute_sql_router)\n",
    "workflow.add_conditional_edges(\"regenerate_query\", check_attempts_router)\n",
    "workflow.add_edge(\"generate_human_readable_answer\", END)\n",
    "\n",
    "app = workflow.compile()\n",
    "\n",
    "# Main execution block\n",
    "if __name__ == \"__main__\":\n",
    "    # --- Step 1: Ensure the database is created from the CSV ---\n",
    "    csv_file_path = r\"C:\\Users\\apran\\Videos\\Cin\\LIBRARY\\SQL Agent for Sensor Data\\ocean_data.csv\"\n",
    "    setup_database_from_csv(csv_filepath=csv_file_path, db_filepath=DB_FILE, table_name=\"ocean_data\")\n",
    "\n",
    "    print(\"\\nSQL Agent for Ocean Data is ready. Ask a question.\")\n",
    "    \n",
    "    # --- Step 2: Define your question ---\n",
    "    user_question = \"what is the depth for latitude 64.33334 and longitude -3.4166667?\"\n",
    "    \n",
    "    inputs = {\"question\": user_question, \"attempts\": 0}\n",
    "    final_answer = None\n",
    "    \n",
    "    # --- Step 3: Run the agent and get the answer ---\n",
    "    print(\"\\n--- Agent Execution Log ---\")\n",
    "    for event in app.stream(inputs):\n",
    "        for key, value in event.items():\n",
    "            print(f\"--- Event: {key} ---\")\n",
    "            print(value)\n",
    "            # Capture the final answer\n",
    "            if key == \"generate_human_readable_answer\":\n",
    "                final_answer = value.get(\"query_result\")\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*50)\n",
    "    print(\"✅ Final Human-Readable Answer:\")\n",
    "    print(\"=\"*50)\n",
    "    if final_answer:\n",
    "        print(final_answer)\n",
    "    else:\n",
    "        print(\"Could not generate a final answer from the workflow.\")\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sqlagent",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.23"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
